{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168be264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, f1_score, auc, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torchvision.utils import save_image\n",
    "from true_classify import *\n",
    "from Utils import *\n",
    "from anonymization_methods import *\n",
    "from datasets import *\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from collections import Counter\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from PIL import ImageDraw\n",
    "import torchshow as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6168b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and testing data directories\n",
    "\n",
    "\n",
    "source_path = 'Path to the data'\n",
    "\n",
    "class_names = [folder for folder in os.listdir(source_path) if os.path.isdir(os.path.join(source_path, folder))]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "file_list = os.listdir(source_path)\n",
    "\n",
    "# if needed to update the code\n",
    "# model_dir = 'The name of the AI model'\n",
    "\n",
    "\n",
    "# the path where the data will be saved\n",
    "output_path = 'path'\n",
    "\n",
    "\n",
    "\n",
    "# save_roc_dir = 'D:/Younas_Work/D2_Final/Results_Final/ROC/ROC Plots Mouth_Masked/'\n",
    "# excel_file_path = 'D:/Younas_Work/D2_Final/Results_Final/Excel_Sheets/Mouth_Masked.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a5f09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d283082",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a64045",
   "metadata": {},
   "outputs": [],
   "source": [
    "Define a new transform with additional data augmentations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.convnext_base(pretrained=True)\n",
    "# model.classifier[2]=nn.Linear(1024,num_classes)\n",
    "\n",
    "# model.load_state_dict(torch.load('Convnext_pretrained_younas.pt'))\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d311191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50893a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Parameter values\n",
    "\n",
    "# we will put all the values to minimize the changes.\n",
    "\n",
    "#For Simple Blur\n",
    "blur_kernel_size = 3\n",
    "\n",
    "#For DP Blur\n",
    "#block\n",
    "b = 16\n",
    "#m & eps are for privacy budget. Larger m = more noise\n",
    "m = 2\n",
    "#eps is the privacy parameter in DP, smaller eps means higher noise and more distortion\n",
    "eps = 100\n",
    "#K is kernel size for gaussian blur. Height and width of the Gaussian kernel\n",
    "k = 9\n",
    "#SD of Gaussian blur. Larger sigma means more blurring\n",
    "sigma = 0\n",
    "\n",
    "#For Simple Pixelate\n",
    "pixel_size = 15\n",
    "\n",
    "\n",
    "#For DP Pixelate\n",
    "#b, m and eps are the same for DP pixelate and DP Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "test_loader = create_test_loader(source_path, batch_size)\n",
    "counter = 0\n",
    "for data, target in local_test_loader:\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    ############ choose the method you need\n",
    "    perturbed = create_blurred_image(data, blur_kernel_size)\n",
    "#     perturbed = create_pixelated_image(data, pixel_size)\n",
    "#     perturbed = create_dp_blurred_image(data, b, m, eps, k, sigma)\n",
    "#     perturbed = create_dp_pixelated_image(data, b, m, eps)\n",
    "#     perturbed = draw_points_on_image(annonymized_image, optimized_gradients[0, 0, :, :] >= 1, point_size=0.05, point_color=(255, 0, 0))\n",
    "#     perturbed =mask_mouth(x, mouth_cascade, ds_factor=0.75)\n",
    "#     perturbed =mask_eyes(x, eye_cascade, radius, color, thickness)\n",
    "    \n",
    "    class_label = target.to(cpu)\n",
    "    class_subfolder = class_names[class_label]            \n",
    "\n",
    "    class_output_path = os.path.join(output_path, class_subfolder)\n",
    "    if not os.path.exists(class_output_path):\n",
    "        os.makedirs(class_output_path)\n",
    "    final_path = os.path.join(class_output_path, str(counter))\n",
    "    ts.save(perturbed,final_path+\".jpg\")\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0facaac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
